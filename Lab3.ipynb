{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten, SimpleRNN, LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv')\n",
    "df.head(10)\n",
    "\n",
    "def getTrainTest(url, splitPercent=0.8):\n",
    "    df = pd.read_csv(url, usecols=[1], engine='python')\n",
    "    print(df)\n",
    "    data = np.array(df.values.astype('float32'))\n",
    "    print(data)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data).flatten()\n",
    "    n = len(data)\n",
    "    # Point for splitting data into train and test\n",
    "    split = int(n * splitPercent)\n",
    "    trainData = data[range(split)]\n",
    "    testData = data[split:]\n",
    "    return trainData, testData, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sunspots\n",
      "0         58.0\n",
      "1         62.6\n",
      "2         70.0\n",
      "3         55.7\n",
      "4         85.0\n",
      "...        ...\n",
      "2815      71.8\n",
      "2816      50.3\n",
      "2817      55.8\n",
      "2818      33.3\n",
      "2819      33.4\n",
      "\n",
      "[2820 rows x 1 columns]\n",
      "[[58. ]\n",
      " [62.6]\n",
      " [70. ]\n",
      " ...\n",
      " [55.8]\n",
      " [33.3]\n",
      " [33.4]]\n"
     ]
    }
   ],
   "source": [
    "sunspotsData = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv'\n",
    "trainData, testData, data = getTrainTest(sunspotsData)\n",
    "\n",
    "def createNN(input_shape, activation):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(\n",
    "        64,\n",
    "        input_shape=input_shape,\n",
    "        activation=activation[0]\n",
    "    ))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(\n",
    "        32,\n",
    "        input_shape=input_shape,\n",
    "        activation=activation[0]\n",
    "    ))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(\n",
    "        1,\n",
    "        input_shape=input_shape,\n",
    "        activation=activation[0]\n",
    "    ))\n",
    "   \n",
    "    model.add(Flatten())\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def createRNN(hidden_units, dense_units, input_shape, activation):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(SimpleRNN(\n",
    "        hidden_units, \n",
    "        input_shape=input_shape, \n",
    "        activation=activation[0]\n",
    "    ))\n",
    "\n",
    "    model.add(Dense(units=dense_units, activation=activation[1]))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def createLSTM(hidden_units, dense_units, input_shape, activation):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        hidden_units, \n",
    "        input_shape=input_shape, \n",
    "        activation=activation[0]\n",
    "    ))\n",
    "\n",
    "    model.add(Dense(units=dense_units, activation=activation[1]))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(dat, timeSteps):\n",
    "    # Indices of target array\n",
    "    indY = np.arange(timeSteps, len(dat), timeSteps)\n",
    "    Y = dat[indY]\n",
    "\n",
    "    # Prepare X\n",
    "    rowsX = len(Y)\n",
    "    X = dat[range(timeSteps * rowsX)]\n",
    "    X = np.reshape(X, (rowsX, timeSteps, 1))   \n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def printError(trainY, testY, trainPredict, testPredict):    \n",
    "    # Error of predictions\n",
    "    trainRMSE = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    testRMSE = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "    trainR2 = r2_score(trainY, trainPredict)\n",
    "    testR2 = r2_score(testY, testPredict)\n",
    "\n",
    "    print('Train RMSE: %.3f RMSE' % (trainRMSE))\n",
    "    print('Test RMSE: %.3f RMSE' % (testRMSE))   \n",
    "    print('Train R2: %.3f R2' % (trainR2))\n",
    "    print('Test R2: %.3f R2' % (testR2))\n",
    " \n",
    "timeSteps = 12\n",
    "trainX, trainY = getXY(trainData, timeSteps)\n",
    "testX, testY = getXY(testData, timeSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "187/187 - 8s - loss: 0.0939 - 8s/epoch - 45ms/step\n",
      "Epoch 2/20\n",
      "187/187 - 8s - loss: 0.0601 - 8s/epoch - 43ms/step\n",
      "Epoch 3/20\n",
      "187/187 - 8s - loss: 0.0462 - 8s/epoch - 43ms/step\n",
      "Epoch 4/20\n",
      "187/187 - 8s - loss: 0.0386 - 8s/epoch - 43ms/step\n",
      "Epoch 5/20\n",
      "187/187 - 8s - loss: 0.0335 - 8s/epoch - 43ms/step\n",
      "Epoch 6/20\n",
      "187/187 - 8s - loss: 0.0287 - 8s/epoch - 43ms/step\n",
      "Epoch 7/20\n",
      "187/187 - 8s - loss: 0.0251 - 8s/epoch - 44ms/step\n",
      "Epoch 8/20\n",
      "187/187 - 8s - loss: 0.0218 - 8s/epoch - 44ms/step\n",
      "Epoch 9/20\n",
      "187/187 - 8s - loss: 0.0191 - 8s/epoch - 44ms/step\n",
      "Epoch 10/20\n",
      "187/187 - 8s - loss: 0.0170 - 8s/epoch - 43ms/step\n",
      "Epoch 11/20\n",
      "187/187 - 8s - loss: 0.0151 - 8s/epoch - 43ms/step\n",
      "Epoch 12/20\n",
      "187/187 - 8s - loss: 0.0138 - 8s/epoch - 43ms/step\n",
      "Epoch 13/20\n",
      "187/187 - 8s - loss: 0.0122 - 8s/epoch - 44ms/step\n",
      "Epoch 14/20\n",
      "187/187 - 8s - loss: 0.0116 - 8s/epoch - 44ms/step\n",
      "Epoch 15/20\n",
      "187/187 - 8s - loss: 0.0107 - 8s/epoch - 44ms/step\n",
      "Epoch 16/20\n",
      "187/187 - 8s - loss: 0.0097 - 8s/epoch - 44ms/step\n",
      "Epoch 17/20\n",
      "187/187 - 8s - loss: 0.0089 - 8s/epoch - 44ms/step\n",
      "Epoch 18/20\n",
      "187/187 - 8s - loss: 0.0083 - 8s/epoch - 43ms/step\n",
      "Epoch 19/20\n",
      "187/187 - 8s - loss: 0.0077 - 8s/epoch - 43ms/step\n",
      "Epoch 20/20\n",
      "187/187 - 8s - loss: 0.0068 - 8s/epoch - 44ms/step\n",
      "Epoch 1/20\n",
      "187/187 - 1s - loss: 0.0071 - 865ms/epoch - 5ms/step\n",
      "Epoch 2/20\n",
      "187/187 - 1s - loss: 0.0055 - 690ms/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "187/187 - 1s - loss: 0.0045 - 688ms/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "187/187 - 1s - loss: 0.0037 - 689ms/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "187/187 - 1s - loss: 0.0037 - 689ms/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "187/187 - 1s - loss: 0.0035 - 687ms/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "187/187 - 1s - loss: 0.0039 - 690ms/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "187/187 - 1s - loss: 0.0031 - 690ms/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "187/187 - 1s - loss: 0.0028 - 688ms/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "187/187 - 1s - loss: 0.0032 - 687ms/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "187/187 - 1s - loss: 0.0029 - 685ms/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "187/187 - 1s - loss: 0.0025 - 681ms/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "187/187 - 1s - loss: 0.0026 - 682ms/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "187/187 - 1s - loss: 0.0029 - 688ms/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "187/187 - 1s - loss: 0.0026 - 694ms/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "187/187 - 1s - loss: 0.0027 - 691ms/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "187/187 - 1s - loss: 0.0024 - 682ms/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "187/187 - 1s - loss: 0.0026 - 682ms/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "187/187 - 1s - loss: 0.0028 - 686ms/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "187/187 - 1s - loss: 0.0025 - 682ms/epoch - 4ms/step\n",
      "Epoch 1/20\n",
      "187/187 - 2s - loss: 0.0292 - 2s/epoch - 10ms/step\n",
      "Epoch 2/20\n",
      "187/187 - 1s - loss: 0.0155 - 1s/epoch - 6ms/step\n",
      "Epoch 3/20\n",
      "187/187 - 1s - loss: 0.0110 - 1s/epoch - 6ms/step\n",
      "Epoch 4/20\n",
      "187/187 - 1s - loss: 0.0069 - 1s/epoch - 6ms/step\n",
      "Epoch 5/20\n",
      "187/187 - 1s - loss: 0.0053 - 1s/epoch - 6ms/step\n",
      "Epoch 6/20\n",
      "187/187 - 1s - loss: 0.0049 - 1s/epoch - 6ms/step\n",
      "Epoch 7/20\n",
      "187/187 - 1s - loss: 0.0047 - 1s/epoch - 6ms/step\n",
      "Epoch 8/20\n",
      "187/187 - 1s - loss: 0.0046 - 1s/epoch - 6ms/step\n",
      "Epoch 9/20\n",
      "187/187 - 1s - loss: 0.0044 - 1s/epoch - 6ms/step\n",
      "Epoch 10/20\n",
      "187/187 - 1s - loss: 0.0044 - 1s/epoch - 6ms/step\n",
      "Epoch 11/20\n",
      "187/187 - 1s - loss: 0.0042 - 1s/epoch - 6ms/step\n",
      "Epoch 12/20\n",
      "187/187 - 1s - loss: 0.0042 - 1s/epoch - 6ms/step\n",
      "Epoch 13/20\n",
      "187/187 - 1s - loss: 0.0040 - 1s/epoch - 6ms/step\n",
      "Epoch 14/20\n",
      "187/187 - 1s - loss: 0.0041 - 1s/epoch - 6ms/step\n",
      "Epoch 15/20\n",
      "187/187 - 1s - loss: 0.0040 - 1s/epoch - 6ms/step\n",
      "Epoch 16/20\n",
      "187/187 - 1s - loss: 0.0039 - 1s/epoch - 6ms/step\n",
      "Epoch 17/20\n",
      "187/187 - 1s - loss: 0.0039 - 1s/epoch - 6ms/step\n",
      "Epoch 18/20\n",
      "187/187 - 1s - loss: 0.0038 - 1s/epoch - 6ms/step\n",
      "Epoch 19/20\n",
      "187/187 - 1s - loss: 0.0037 - 1s/epoch - 6ms/step\n",
      "Epoch 20/20\n",
      "187/187 - 1s - loss: 0.0037 - 1s/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "modelRNN = createRNN(hidden_units=3, dense_units=1, input_shape=(timeSteps,1), activation=['tanh', 'tanh'])\n",
    "modelNN = createNN(input_shape=(timeSteps,1), activation=['relu', 'relu'])\n",
    "modelLSTM = createLSTM(hidden_units=3, dense_units=1, input_shape=(timeSteps,1), activation=['tanh', 'tanh'])\n",
    "\n",
    "timeStartRNN = time.time()\n",
    "modelRNN.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2)\n",
    "timeEndRNN = time.time()\n",
    "\n",
    "timeStartNN = time.time()\n",
    "modelNN.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2)\n",
    "timeEndNN = time.time()\n",
    "\n",
    "timeStartLSTM = time.time()\n",
    "modelLSTM.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2)\n",
    "timeEndLSTM = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "6/6 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 23ms/step\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "\n",
      "NN\n",
      "Train RMSE: 0.048 RMSE\n",
      "Test RMSE: 0.074 RMSE\n",
      "Train R2: 0.892 R2\n",
      "Test R2: 0.880 R2\n",
      "Time:  13.962080955505371\n",
      "\n",
      "RNN\n",
      "Train RMSE: 0.079 RMSE\n",
      "Test RMSE: 0.120 RMSE\n",
      "Train R2: 0.704 R2\n",
      "Test R2: 0.690 R2\n",
      "Time:  162.77355217933655\n",
      "\n",
      "LSTM\n",
      "Train RMSE: 0.061 RMSE\n",
      "Test RMSE: 0.088 RMSE\n",
      "Train R2: 0.822 R2\n",
      "Test R2: 0.833 R2\n",
      "Time:  23.13651204109192\n"
     ]
    }
   ],
   "source": [
    "trainPredictNN = modelNN.predict(trainX)\n",
    "testPredictNN = modelNN.predict(testX)\n",
    "\n",
    "trainPredictRNN = modelRNN.predict(trainX)\n",
    "testPredictRNN = modelRNN.predict(testX)\n",
    "\n",
    "trainPredictLSTM = modelLSTM.predict(trainX)\n",
    "testPredictLSTM = modelLSTM.predict(testX)\n",
    "\n",
    "print('\\nNN')\n",
    "printError(trainY, testY, trainPredictNN, testPredictNN)\n",
    "print('Time: ', timeEndNN - timeStartNN)\n",
    "\n",
    "print('\\nRNN')\n",
    "printError(trainY, testY, trainPredictRNN, testPredictRNN)\n",
    "print('Time: ', timeEndRNN - timeStartRNN)\n",
    "\n",
    "print('\\nLSTM')\n",
    "printError(trainY, testY, trainPredictLSTM, testPredictLSTM)\n",
    "print('Time: ', timeEndLSTM - timeStartLSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados de NN\n",
    "Valor RMSE de prueba: 0.074\n",
    "Valor R cuadrado de prueba: 0.88\n",
    "El 88% de los cambios de las variables dependientes se explican por los cambios de las variables independientes.\n",
    "\n",
    "Pros de NN:\n",
    "- Es la estructura que obtiene los mejores resultados.\n",
    "- Menor tiempo de entrenamiento.\n",
    "\n",
    "Contras de NN:\n",
    "- Puede presentar un poco de overfitting.\n",
    "- Requiere de un mayor número de capas ocultas para obtener buenos resultados.\n",
    "\n",
    "### Resultados de RNN\n",
    "Valor RMSE de prueba: 0.12\n",
    "Valor R cuadrado de prueba: 0.69\n",
    "El 84.7% de los cambios de las variables dependientes se explican por los cambios de las variables independientes.\n",
    "\n",
    "Pros de RNN:\n",
    "- Obtiene resultados casi tan buenos como los de NN.\n",
    "- Requiere de un menor número de capas ocultas para obtener buenos resultados.\n",
    "\n",
    "Contras de RNN:\n",
    "- Puede presentar un poco de overfitting.\n",
    "- Tiempo de entrenamiento mayor que el de los otros modelos.\n",
    "\n",
    "### Resultados de LSTM\n",
    "Valor RMSE de prueba: 0.088\n",
    "Valor R cuadrado de prueba: 0.833\n",
    "El 82.1% de los cambios de las variables dependientes se explican por los cambios de las variables independientes.\n",
    "\n",
    "Pros de LSTM:\n",
    "- Requiere de un menor número de capas ocultas.\n",
    "- Tiempo de entrenamiento menor que el de RNN.\n",
    "\n",
    "Contras de LSTM:\n",
    "- Obtiene resultados peores que los de NN y RNN.\n",
    "- Puede presentar un poco de overfitting.\n",
    "\n",
    "### Estructura óptima\n",
    "Según los resultados obtenidos, la estructura Feed Forward Neural Network es la óptima para este problema, con un valor R cuadrado de 0.88 y un RMSE de 0.074 en los datos de prueba. Al comparar con la teória, se puede concluir que la estructura de la red neuronal recurrente no es la más adecuada para este tipo de problemas, ya que está diseñada para trabajar con datos secuenciales, como series de tiempo. En este caso, los datos no son secuenciales, por lo que la red neuronal recurrente no es la más adecuada para este problema. De similar manera, la estructura LSTM tampoco es la adecuada para este tipo de problemas, ya que también está diseñada para trabajar con datos secuenciales. Adicionalmente, la red neuronal LSTM está diseñada para trabajar con datos secuenciales que tienen una dependencia a largo plazo. En otras palabras, está diseñada para trabajar con datos en los cuales los datos de entrada tienen una dependencia con los datos de entrada de hace mucho tiempo. En este caso, los datos no tienen una dependencia a largo plazo, por lo que la red neuronal LSTM no es la más adecuada para este problema. Finalmente, la estructura Feed Forward Neural Network es la más adecuada para este problema, ya que los datos no son secuenciales y no tienen una dependencia a largo plazo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
